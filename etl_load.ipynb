{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff84f387",
   "metadata": {},
   "source": [
    "# 1: Load Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb5375be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import required libraries\n",
    "import pandas as pd         # For data handling\n",
    "import sqlite3              # For working with SQLite databases\n",
    "import os                   # For directory and file handling\n",
    "\n",
    "# Create a folder named 'loaded_data' if it doesn't already exist\n",
    "# This is where we'll save the SQLite DB files\n",
    "os.makedirs(\"loaded_data\", exist_ok=True)\n",
    "\n",
    "# Define the path to the transformed CSV files\n",
    "full_csv_path = \"transformed_full.csv\"\n",
    "incr_csv_path = \"transformed_incremental.csv\"\n",
    "\n",
    "# Define the destination SQLite database file paths\n",
    "sqlite_full_db = \"loaded_data/full_data.db\"\n",
    "sqlite_incr_db = \"loaded_data/incremental_data.db\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc5755a",
   "metadata": {},
   "source": [
    "#  2: Load Full Transformed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4e6529e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Full dataset loaded into 'full_data.db' successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the transformed full dataset into a pandas DataFrame\n",
    "df_full = pd.read_csv(full_csv_path)\n",
    "\n",
    "# Connect to the SQLite database for full data (will create the file if it doesn't exist)\n",
    "conn_full = sqlite3.connect(sqlite_full_db)\n",
    "\n",
    "# Write the full DataFrame to a new table named 'full_data' in the SQLite database\n",
    "# If the table already exists, it will be replaced\n",
    "df_full.to_sql(\"full_data\", conn_full, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Print success message\n",
    "print(\" Full dataset loaded into 'full_data.db' successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f512cb",
   "metadata": {},
   "source": [
    "# 3: Load Incremental Transformed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2308806e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Incremental dataset loaded into 'incremental_data.db' successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the transformed incremental dataset into a pandas DataFrame\n",
    "df_incr = pd.read_csv(incr_csv_path)\n",
    "\n",
    "# Connect to the SQLite database for incremental data (will create the file if it doesn't exist)\n",
    "conn_incr = sqlite3.connect(sqlite_incr_db)\n",
    "\n",
    "# Write the incremental DataFrame to a new table named 'incremental_data'\n",
    "# If the table already exists, it will be replaced\n",
    "df_incr.to_sql(\"incremental_data\", conn_incr, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Print success message\n",
    "print(\" Incremental dataset loaded into 'incremental_data.db' successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d8b494",
   "metadata": {},
   "source": [
    "# 4: Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05b1a755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of full_data table:\n",
      "   review_id  product  rating review_date         last_updated  \\\n",
      "0       1000    Phone       3  2025-04-01  2025-04-01 07:48:00   \n",
      "1       1001  Monitor       5  2025-04-02  2025-04-02 17:18:00   \n",
      "2       1002   Laptop       4  2025-04-03  2025-04-03 06:30:00   \n",
      "3       1003   Tablet       2  2025-04-04  2025-04-04 22:18:00   \n",
      "4       1004  Monitor       4  2025-04-05  2025-04-05 07:13:00   \n",
      "\n",
      "   review_age_days rating_category  \n",
      "0               75          Medium  \n",
      "1               74            High  \n",
      "2               73            High  \n",
      "3               72             Low  \n",
      "4               71            High  \n",
      " Preview of incremental_data table:\n",
      "Empty DataFrame\n",
      "Columns: [review_id, product, rating, review_date, last_updated, review_age_days, rating_category]\n",
      "Index: []\n",
      "All data loaded and verified successfully.\n"
     ]
    }
   ],
   "source": [
    "# Read and display the first 5 rows from the 'full_data' table in the full_data.db SQLite database\n",
    "print(\"Preview of full_data table:\")\n",
    "print(pd.read_sql(\"SELECT * FROM full_data LIMIT 5\", conn_full))\n",
    "\n",
    "# Read and display the first 5 rows from the 'incremental_data' table in the incremental_data.db SQLite database\n",
    "print(\" Preview of incremental_data table:\")\n",
    "print(pd.read_sql(\"SELECT * FROM incremental_data LIMIT 5\", conn_incr))\n",
    "\n",
    "# Close the SQLite database connections\n",
    "conn_full.close()\n",
    "conn_incr.close()\n",
    "\n",
    "# Final confirmation\n",
    "print(\"All data loaded and verified successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
